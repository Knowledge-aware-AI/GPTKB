# Welcome to GPTKB

## Overview
GPTKB is a large general-domain knowledge base (KB) entirely from a large language model (LLM). It demonstrates the feasibility of large-scale KB construction from LLMs, while highlighting specific challenges arising around entity recognition, entity and property canonicalization, and taxonomy construction.

Based on GPT-4o-mini, GPTKB contains 101 million triples for more than 2.9 million entities, at a cost 100x less than previous KBC projects.

GPTKB is a landmark for two fields:
- For NLP, for the first time, it provides constructive insights into the knowledge (or beliefs) of LLMs.
- For the Semantic Web, it shows novel ways forward for the long-standing challenge of general-domain KB construction.

This repository contains the code for KB construction from LLMs to materialize entity-centric parametric knowledge of LLMs.

## Getting Started
### Install 

### Run

## Project Page
(https://gptkb.org/)[https://gptkb.org/]

## Citation
If you use this work please cite our paper:
```bibtex
@article{hu2024gptkb,
  title={GPTKB: Building Very Large Knowledge Bases from Language Models},
  author={Hu, Yujia and Nguyen, Tuan-Phong and Ghosh, Shrestha and Razniewski, Simon},
  journal={arXiv preprint arXiv:2411.04920},
  year={2024}
}
```
